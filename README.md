# Own VisionLLM
The purpose of this project is to develop a custom VisionLLM with a specific focus.
I will use the GPT-4 API for the language model component and ImageNet as the image decoder.
I plan to create the link between the LLM and ImageNet, building my own language-guided image tokenizer. 
This system will receive and interpret both image and language tokens to perform specific instructions based on text queries.
Ultimately, I am developing a GPT-powered wrapper or an LLM-based, open-ended task decoder that will generate the desired output based on the given image and text query.
